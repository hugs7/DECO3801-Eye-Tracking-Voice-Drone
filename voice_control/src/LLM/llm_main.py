"""
Main logic for running the terminal agent in the Local Language Model (LLM) system.
"""

from typing import List, Dict, Optional

from omegaconf import OmegaConf
import openai

from common.logger_helper import init_logger

from .core import AgentInteractiveConsole, react
from .defaults import init_context
from .wrappers import done, proxy_input
from .formatting import remove_code_block_formatting


logger = init_logger()


class LLM:
    def __init__(self, llm_config: OmegaConf):
        self.config = llm_config

        self.__check_config()

    def __check_config(self):
        if "model" not in self.config:
            raise ValueError("The model parameter is required in the LLM configuration.")

        if "temperature" not in self.config:
            raise ValueError("The temperature parameter is required in the LLM configuration.")

    def ask_fn(self, context: List[Dict[str, str]]) -> str:
        """
        Sends a chat completion request to the OpenAI API using the specified model and returns the response.

        Args:
            context (List[Dict[str, str]]): A list of dictionaries representing the conversation history.
                                            Each dictionary should contain keys like 'role' and 'content'.

        Returns:
            str: The content of the response from the OpenAI API.
        """
        response = openai.ChatCompletion.create(model=self.config.model, temperature=self.config.temperature, messages=context)
        terminal_code = response["choices"][0]["message"]["content"]
        clean_code = remove_code_block_formatting(terminal_code)
        return clean_code

    def run_terminal_agent(self, user_input: str) -> Optional[str]:
        """
        Runs an interactive terminal agent that reacts to user input and executes commands in a console environment.
        If no user input is provided, the function will return empty output.

        Args:
            user_input (str): The initial user input. Can be an empty string.

        Returns:
            Optional[str]: The output generated by the agent in response to the user's command. None if no command is given.
        """

        if not user_input:
            return None

        interactive_console = AgentInteractiveConsole(locals={"done": done, "input": proxy_input})
        context = init_context()

        user_command = f">>> # User: {user_input}"
        _, _, output = react(interactive_console, self.ask_fn, context, user_command)

        return output


if __name__ == "__main__":
    llm_config = OmegaConf.create({"model": "gpt-4o-mini"})
    llm = LLM(llm_config)
    llm.run_terminal_agent()
